---
title: "Mouse Cerebellum 001 - Barcode QC with ArchR"
author: "Ioannis Sarropoulos"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output: html_document
---

```{r}
suppressPackageStartupMessages({
  library(ArchR)
  library(tidyverse)
  library(RColorBrewer)
})
```

Initialising ArchR

```{r}
addArchRThreads(threads = 40) 

## Working directory. This is where the arrow files will be generated and stored.
setwd("~/Mouse_Cereb/")

## Genome and annotation
addArchRGenome("mm10")
```

Reading in the fragment files for the mouse cerebellum data and creating the respective arrow files

```{r}
samples <- list.files("~/sds/sd17d003/scATAC/Cerebellum/Mouse/", pattern = "^sa.*", include.dirs = T)

bad_samples <- list.files("~/sds/sd17d003/scATAC/Cerebellum/Mouse/bad_samples/", pattern = "^sa.*", include.dirs = T)

samples <- samples[!(samples %in% bad_samples)]

sample.info <- data.frame(sample=samples, s_split=samples,stringsAsFactors = F) %>%
  separate(s_split, into = c("lib", "species", "tissue", "timepoint", "sex"), sep = "_")

inputFiles <- sapply(samples, function(x) paste0("~/sds/sd17d003/scATAC/Cerebellum/Mouse/",x, "/cellranger/", x, "/outs/fragments.tsv.gz"))

length(samples)
print(samples)
```

Now creating the arrow files and filtering for high quality cells.

We will require high quality barcodes to have at least 5,000 fragments and a TSS enrichment of 3.

```{r}
if (dir.exists("001_barcode_qc")==F){
  dir.create("001_barcode_qc")
}

ArrowFiles <- createArrowFiles(
  inputFiles = inputFiles,
  sampleNames = names(inputFiles),
  filterTSS = 3, 
  filterFrags = 5000, 
  addTileMat = TRUE,
  addGeneScoreMat = TRUE,
  QCDir = "001_barcode_qc",
  promoterRegion = c(2000,100),
  removeFilteredCells = T,
  minFrags = 2500, 
  force = T
)
```

Within each sample, we will also identify doublets. For this we will be using simulated doublets and identifying their neighbours in the LSI space.

Throughout this project, we are using the TF-(logIDF) LSI method as introduced by Cusanovich et al.
We don't scale LSI components (i.e. each is proportional to its variance) but remove components with more than 0.75 correlation with sequencing depth.

Here, we will be using 50 dimensions, 10 iterations and label the 10 NNs to each doublet.

```{r}
if (dir.exists("002_doublets")==F){
  dir.create("002_doublets")
}

doubScores <- addDoubletScores(
  input = ArrowFiles,
  k = 10, #Refers to how many cells near a "pseudo-doublet" to count.
  knnMethod = "LSI", #Refers to the embedding to use for nearest neighbor search.
  LSIMethod = 1,
  dimsToUse = 1:50,
  nTrials = 10,
  scaleDims = F,
  LSIParams = list(seed = 1,
                   varFeatures = 50000,
                   excludeChr = c("chrX", "chrY", "chrMT")),
  outDir = "002_doublets"
)
```

```{r}
ArrowFiles <- list.files("~/Mouse_Cereb/", pattern = ".arrow")
```

Now we can initialize the project:

```{r}
proj <- ArchRProject(
  ArrowFiles = ArrowFiles, 
  outputDirectory = "proj1_init",
  copyArrows = TRUE #This is recommened so that you maintain an unaltered copy for later usage.
)

## Also adding more metadata
proj$cellNames_short <- sapply(getCellNames(proj), function(x) {
  paste(str_extract(x, "sa[0-9]*"), str_split(x, pattern = fixed("#"), simplify = T)[2], sep="_")
})

proj$Sample_short <- sapply(proj$Sample, function(x) {
  x <- paste(str_split(x, pattern = fixed("_"), simplify = T)[c(4, 1, 5)], collapse="_")
  x <- gsub("P4", "P04", x)
  x <- gsub("P7", "P07", x)
})

proj$Timepoint <- sapply(proj$Sample_short, function(x) str_split(x, pattern = fixed("_"), simplify = T)[1])
proj$Lib <- sapply(proj$Sample_short, function(x) str_split(x, pattern = fixed("_"), simplify = T)[2])
proj$Sex <- sapply(proj$Sample_short, function(x) str_split(x, pattern = fixed("_"), simplify = T)[3])
```

How many cells passed QC? Start keeping records for them:

```{r}
nCells(proj)
barcodes_init <- getCellColData(proj) %>%
  as.data.frame() %>%
  rownames_to_column("barcode")
```

Filtering putative doublets (pass 1).
Here we want to be relatively lenient, so we select a ratio of 1 (i.e. filtering top 5% of barcodes for a sample of 5,000 cells).

We are using Doublet enrichment as a cutoff.

```{r}
proj <- filterDoublets(ArchRProj = proj,
                       filterRatio = 1)
```

Updating these barcodes in our log file:

```{r}
nCells(proj)
barcodes_init$Doublet_1stPass <- !(barcodes_init$barcode %in% getCellNames(proj))
```

Now we can calculate our first iterative LSI. We are now extending our dimensions to 100 and the number of variable features to 100K.

```{r}
proj <- addIterativeLSI(ArchRProj = proj,
                        useMatrix = "TileMatrix",
                        name = "IterativeLSI_qc",
                        iterations=5,
                        clusterParams = list(
                          resolution = c(0.1, 0.2, 0.4, 0.8), 
                          sampleCells = 20000, 
                          n.start = 10
                        ), 
                        varFeatures = 100000,
                        dimsToUse = 1:100,
                        totalFeatures = 500000,
                        seed = 1,
                        LSIMethod = 1,
                        scaleDims = FALSE,
                        corCutOff = 0.75,
                        excludeChr = c("chrX", "chrY", "chrMT"),
                        binarize = T,
                        force = T)
```

Clustering: The goal here is to identify clusters enriched for doublets/ low quality cells.
For this we should go for a relatively high resolution (2.0) for Seurat Louvain clustering.

```{r}
proj <- addClusters(input = proj,
                    name = "Clusters_qc",
                    reducedDims = "IterativeLSI_qc",
                    method = "Seurat",
                    force = T,
                    resolution=2,
                    corCutOff = 0.75,
                    scaleDims = FALSE,
                    seed = 1)

## Adding these clusters to the barcode stats
barcodes_init <- getCellColData(proj, select = "Clusters_qc") %>%
  as.data.frame() %>%
  rownames_to_column("barcode") %>%
  right_join(barcodes_init)
```

We can also run a UMAP to allow us to visualise the distribution of putative doublets/ low quality cells.

```{r}
proj <- addUMAP(ArchRProj = proj,
                name = "UMAP_qc",
                reducedDims = "IterativeLSI_qc",
                minDist = 0.2,
                metric = "cosine",
                nNeighbors = 25,
                force = T,
                seed = 1,
                scaleDims = F,
                corCutOff = 0.75)
```

Now we can have a look into the UMAP:

```{r}
p1 <- plotEmbedding(ArchRProj = proj, colorBy = "cellColData", name = "Sample_short", embedding = "UMAP_qc", pal = rev(colorRampPalette(brewer.pal(11, "Spectral"))(22)), rastr = T, labelMeans = F)
p2 <- plotEmbedding(ArchRProj = proj, colorBy = "cellColData", name = "Clusters_qc", embedding = "UMAP_qc", rastr = T)

ggAlignPlots(p1, p2, type = "h")
```

```{r}
if (dir.exists("Figures/001_QC")==F){
  dir.create("Figures/001_QC")
}

pdf("Figures/001_QC/Mouse_atac_LSI_pass1_tiles_bySample.pdf", width = 8, height = 8, useDingbats = F); print(p1);dev.off()

pdf("Figures/001_QC/Mouse_atac_LSI_pass1_tiles_byCluster.pdf", width = 8, height = 8, useDingbats = F); print(p2);dev.off()
```

Let's also plot some genes

```{r}
interesting_genes <- c("Atoh1", "Sox2", "Foxp2", "Cdon", "Gad2", "Sox14", "Tlx3", "Lmx1a", "Eomes", "Pax2", "Top2a", "Ptf1a", "Kirrel2", "Rora", "Rorb", "Slc17a6", "Meis2", "Aqp4", "Olig2", "Cbln3", "Fgf3", "Grin2b", "Neurod1", "Nhlh1", "Gdf10", "Fabp7", "Map3k1", "Gli2", "Esrrg", "Sorcs3", "Cdh22", "Etv1", "Junb", "Mef2a", "Foxp1", "Cdh9", "March11", "Pvalb", "Lhx2", "Pax5", "Syndig1l","Gabra6", "Slc1a3", "Inpp5d")

p <- plotEmbedding(
    ArchRProj = proj, 
    colorBy = "GeneScoreMatrix", 
    name = interesting_genes, 
    embedding = "UMAP_qc",
    quantCut = c(0.01, 0.95),
    imputeWeights = NULL
)

p
```

Let's also explore some QC stats:

```{r, fig.width=8, fig.height=8}
## TSS enrichment
p <- plotEmbedding(ArchRProj = proj, colorBy = "cellColData", name = "TSSEnrichment", embedding = "UMAP_qc", rastr = T)
p
pdf("Figures/001_QC/Mouse_atac_LSI_pass1_tiles_TSSenrichment.pdf", width = 8, height = 8, useDingbats = F); print(p);dev.off()

## Doublet score
p <- plotEmbedding(ArchRProj = proj, colorBy = "cellColData", name = "DoubletScore", embedding = "UMAP_qc", rastr = T)
p
pdf("Figures/001_QC/Mouse_atac_LSI_pass1_tiles_DoubletScore.pdf", width = 8, height = 8, useDingbats = F); print(p);dev.off()


## Doublet enrichment
p <- plotEmbedding(ArchRProj = proj, colorBy = "cellColData", name = "DoubletEnrichment", embedding = "UMAP_qc", rastr = T)
p
pdf("Figures/001_QC/Mouse_atac_LSI_pass1_tiles_DoubletEnrichment.pdf", width = 8, height = 8, useDingbats = F); print(p);dev.off()

## nFragments
p <- plotEmbedding(ArchRProj = proj, colorBy = "cellColData", name = "nFrags", embedding = "UMAP_qc", rastr = T)
p
pdf("Figures/001_QC/Mouse_atac_LSI_pass1_tiles_nFrags.pdf", width = 8, height = 8, useDingbats = F); print(p);dev.off()
```

We see that we still have some putative doublets/ low quality cells that cluster together.

Let's apply a second filter, removing all cells with more than 45K fragment (~2x the median of all cells) or more than 4 doublet enrichment score.

```{r, fig.width=6, fig.height=6}
hist(proj$nFrags, breaks = 100, main = "Number of fragments")
abline(v = median(proj$nFrags), col="deepskyblue3", lty="dashed")

p <- ggPoint(x=proj$nFrags,
        y=proj$DoubletEnrichment,
        colorDensity = T,
        rastr = T) +
  geom_hline(yintercept = 4, col="red", lty="dashed") +
  geom_vline(xintercept = 45000, col="red", lty="dashed") +
  xlab("nFragments") +
  ylab("DoubletEnrichment")

p

pdf("Figures/001_QC/Putative_Doublets_filteredBy45Kfrags_andDoubEnr4.pdf", width = 6, height = 6, useDingbats = F); print(p);dev.off()

put_doublets <- proj$cellNames[proj$nFrags > 45000 |proj$DoubletEnrichment > 4]

write(put_doublets, "002_doublets/Mou_Cer_additional_put_doublets_Frag45K_DoubEnr4.txt")

length(put_doublets)

barcodes_init$Doublet_2ndPass <- barcodes_init$barcode %in% put_doublets
```

Also marking the clusters which were enriched for these likely doublets as spurious

```{r, fig.width=10, fig.height=4}
doub_enrich <- group_by(barcodes_init, Clusters_qc) %>%
  summarise(Doub_freq=sum(barcode %in% put_doublets)/length(barcode)) %>%
  arrange(desc(Doub_freq)) %>%
  mutate(Clusters_qc=factor(Clusters_qc, levels = unique(Clusters_qc)))
  
p <- ggplot(doub_enrich, aes(x=Clusters_qc, y=Doub_freq)) +
  geom_bar(stat="identity") +
  ylab("Fraction of cells as putative doublets") +
  geom_hline(yintercept = 0.30, color="red", lty="dashed") +
  theme_classic() +
  theme(axis.text.x = element_text(angle=45, hjust = 0.9))

p 

pdf("Figures/001_QC/SpuriousClusters_putDoub_Freq.pdf", width = 8, height = 4, useDingbats = F); print(p);dev.off()

spurious_clust <- as.character(doub_enrich$Clusters_qc[doub_enrich$Doub_freq > 0.3])

spurious_cells <- proj$cellNames[proj$Clusters_qc %in% spurious_clust]

length(spurious_cells[!(spurious_cells %in% put_doublets)])

p <- ggplot(data = NULL, aes(x=proj$Clusters_qc[!(proj$cellNames %in% put_doublets)], y=log10(proj$nFrags[!(proj$cellNames %in% put_doublets)]), fill=as.factor(proj$Clusters_qc[!(proj$cellNames %in% put_doublets)] %in% spurious_clust))) +
  geom_violin() +
  geom_boxplot(notch = T, width=0.2, alpha=0) +
  scale_fill_manual(values = c("deepskyblue3", "indianred"), name="Spurious\ncluster") +
  theme_classic()+
  ylab("log10 number of fragments") +
  xlab("Clusters (put. doublets removed") +
  theme(axis.text.x = element_text(angle=45, hjust = 0.9))

p

pdf("Figures/001_QC/SpuriousClusters_nFrag_distribution.pdf", width = 10, height = 4, useDingbats = F); print(p);dev.off()

write(spurious_clust, "002_doublets/Mou_Cer_clustersEnriched_in_putDoublets.txt")
write(spurious_cells, "002_doublets/Mou_Cer_cells_in_clustersEnriched_in_putDoublets.txt")
```

Let's save the project

```{r}
saveArchRProject(proj)
```

To decide whether we need to remove the spurious clusters entirely, let's remove the putative doublets and look for marker genes. Do we find any marker genes for the spurious clusters? Or are they simply aggregates of doublets/low quality cells?

```{r}
proj_sub <- subsetCells(proj, cellNames = proj$cellNames[!(proj$cellNames %in% put_doublets)])

markersGS_clusters_1st_pass <-getMarkerFeatures(proj_sub,
                  groupBy = "Clusters_qc",
                  useMatrix = "GeneScoreMatrix", 
                  threads = 40,
                  scaleTo = 10^4)

saveRDS(markersGS_clusters_1st_pass, "002_doublets/Mou_Cer_1stPass_Cluster_markerGenes.rds")
```

We will not be saving proj_sub yet. We will examine these marker genes in the next section and decide whether we want to only remove the putative doublets or also entirely excude some of the spurious clusters.

Also exporting the barcode stats.

```{r}
saveRDS(barcodes_init, "001_barcode_qc/Mouse_Cerebellum_barcode_stats.rds")
```


```{r}
sessionInfo()
```